---
title: 'vector space & analogy: briefly'
author: ''
date: '2020-07-03'
slug: vector-space-analogy-briefly
categories: []
tags: []
---



<p>A brief guide for using the vector offset method to evaluate efficacy of vector space models in solving word analogy problems. Using the <code>text2vec</code> R-based NLP framework, and two analogy tests for evaluation: Mikolov et al. (2013) &amp; Gladkova et al. (2016).</p>
<div id="sample-vector-space-model" class="section level2">
<h2>Sample vector space model</h2>
<p>For demonstration purposes, we (re-)use a model based on Google n-gram data (circa 1983-2008); available <a href="https://github.com/jaytimm/google_ngrams_and_R/tree/master/google_one_percent_embeddings">here</a>. Model: PPMI-SVD; model details: window size = 5x5, dimensions = 250.</p>
<pre class="r"><code>setwd(local_ngram)
qvec &lt;- readRDS(&#39;Q-[1983,2008].rds&#39;)
rownames(qvec) &lt;- tolower(rownames(qvec))

# scale to 0-1 
qvec &lt;- apply(qvec, 
              MARGIN = 2, 
              FUN = function(X) (X - min(X))/diff(range(X)))

str(qvec) # a numerical matrix -- </code></pre>
<pre><code>##  num [1:16354, 1:250] 0.754 0.829 0.93 0.715 0.743 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ : chr [1:16354] &quot;aaron&quot; &quot;ab&quot; &quot;aback&quot; &quot;abandon&quot; ...
##   ..$ : chr [1:250] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</code></pre>
</div>
<div id="analogy-datasets" class="section level2">
<h2>Analogy datasets</h2>
<p><a href="https://aclweb.org/aclwiki/Analogy_(State_of_the_art)">Several analogy datasets</a> have been developed over the past decade or so. The <a href="https://aclweb.org/aclwiki/Google_analogy_test_set_(State_of_the_art)">Google analogy set</a> is (more or less) the standard. <code>text2vec</code> functions for analogy testing have been developed specifically with this dataset in mind.</p>
<div id="google-mikolov-2013" class="section level3">
<h3>Google (Mikolov 2013)</h3>
<p>Sample set of analogies (along with category header):</p>
<pre class="r"><code>egs &lt;- readLines(google_local_file)
head(egs)</code></pre>
<pre><code>## [1] &quot;: capital-common-countries&quot;     &quot;Athens Greece Baghdad Iraq&quot;    
## [3] &quot;Athens Greece Bangkok Thailand&quot; &quot;Athens Greece Beijing China&quot;   
## [5] &quot;Athens Greece Berlin Germany&quot;   &quot;Athens Greece Bern Switzerland&quot;</code></pre>
<pre class="r"><code>google_analogy_set &lt;- text2vec::prepare_analogy_questions(
        questions_file_path = google_local_file, 
        vocab_terms = rownames(qvec)) </code></pre>
<pre><code>## INFO  [21:05:28.290] 7423 full questions found out of 19544 total</code></pre>
</div>
<div id="bats-gladkova-et-al-2016" class="section level3">
<h3>BATS (Gladkova et al 2016)</h3>
<p><a href="https://aclweb.org/aclwiki/Bigger_analogy_test_set_(State_of_the_art)">Dataset &amp; description</a>. Data have been re-shaped in Google format. Analogies with more than one “correct answer” have been eliminated; hence, dataset presented here is decidedly smaller than original.</p>
<pre class="r"><code>bats_analogy_set &lt;- text2vec::prepare_analogy_questions(
        questions_file_path = bats_local_file, 
        vocab_terms = rownames(qvec)) </code></pre>
<pre><code>## INFO  [21:05:28.640] 25566 full questions found out of 56036 total</code></pre>
</div>
<div id="a-summary" class="section level3">
<h3>A summary</h3>
<pre class="r"><code>library(tidyverse)
ans1 &lt;- lapply(c(bats_local_file, google_local_file), 
               read.csv, header = F) 
names(ans1) &lt;- c(&#39;bats&#39;, &#39;google&#39;)

analogy_summary &lt;- ans1 %&gt;%
  bind_rows(.id = &#39;dataset&#39;) %&gt;%
  mutate(category = ifelse(grepl(&#39;:&#39;, V1), V1, NA)) %&gt;%
  fill(category) %&gt;%
  filter(V1 != category) %&gt;%
  mutate(category = tolower(gsub(&#39;: &#39;, &#39;&#39;, category))) %&gt;%
  rename(analogy = V1) %&gt;%
  group_by(dataset, category) %&gt;%
  mutate(all_n = length(analogy)) %&gt;%
  sample_n(1) %&gt;%
  ungroup() %&gt;%
  select(dataset, category, analogy, all_n) %&gt;%
  mutate(analogy = gsub(&#39; &#39;, &#39;:&#39;, analogy),
         analogy = gsub(&quot;([^:]+:[^:]+):&quot;, &quot;\\1 | &quot;, analogy))</code></pre>
</div>
</div>
<div id="test" class="section level2">
<h2>Test</h2>
<p>Via the <code>text2vec::check_analogy_accuracy</code> function:</p>
<pre class="r"><code>x &lt;- c(google_analogy_set, bats_analogy_set)
y &lt;- Filter(function(x) length(x) &gt; 50, x)
  
res &lt;- text2vec::check_analogy_accuracy(
  questions_list = y, 
  m_word_vectors = qvec)</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>Tables below summarize the accuracy of the n-gram-based VSM on Google/BATS categories. Y = # correct; per_Y = accuracy.</p>
<div id="overview" class="section level3">
<h3>Overview</h3>
<pre class="r"><code>res %&gt;%
  left_join(analogy_summary) %&gt;%
  mutate(correct = ifelse(predicted == actual, &#39;Y&#39;, &#39;N&#39;)) %&gt;%
  group_by(dataset, correct) %&gt;%
  summarize(n = n()) %&gt;%
  ungroup() %&gt;%
  spread(correct, n) %&gt;%
  mutate(per_correct = round(Y/(Y+N)*100, 1)) %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">dataset</th>
<th align="right">N</th>
<th align="right">Y</th>
<th align="right">per_correct</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bats</td>
<td align="right">22392</td>
<td align="right">3146</td>
<td align="right">12.3</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="right">5931</td>
<td align="right">1492</td>
<td align="right">20.1</td>
</tr>
</tbody>
</table>
</div>
<div id="by-category" class="section level3">
<h3>By category</h3>
<pre class="r"><code>res %&gt;%
  mutate(correct = ifelse(predicted == actual, &#39;Y&#39;, &#39;N&#39;)) %&gt;%
  group_by(category, correct) %&gt;%
  summarize(n = n()) %&gt;%
  spread(correct, n) %&gt;%
  mutate(Y = ifelse(is.na(Y), 0, Y),
         total = Y+N,
         per_Y = round(Y/total*100, 1)) %&gt;%
  full_join(analogy_summary) %&gt;%
  mutate(category = gsub(&#39;^.*/|: &#39;, &#39;&#39;, category)) %&gt;%
  select(dataset, category, analogy, total, Y, per_Y) %&gt;%
  arrange(dataset, category) %&gt;%
  knitr::kable()</code></pre>
<table>
<colgroup>
<col width="7%" />
<col width="26%" />
<col width="51%" />
<col width="5%" />
<col width="3%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">dataset</th>
<th align="left">category</th>
<th align="left">analogy</th>
<th align="right">total</th>
<th align="right">Y</th>
<th align="right">per_Y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bats</td>
<td align="left">d01[noun+less_reg]</td>
<td align="left">luck:luckless | breath:breathless</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">d02[un+adj_reg]</td>
<td align="left">conditional:unconditional | known:unknown</td>
<td align="right">992</td>
<td align="right">79</td>
<td align="right">8.0</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">d03[adj+ly_reg]</td>
<td align="left">internal:internally | practical:practically</td>
<td align="right">1190</td>
<td align="right">12</td>
<td align="right">1.0</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">d05[adj+ness_reg]</td>
<td align="left">devoted:devotedness | extensive:extensiveness</td>
<td align="right">272</td>
<td align="right">4</td>
<td align="right">1.5</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">d06[re+verb_reg]</td>
<td align="left">occur:reoccur | deem:redeem</td>
<td align="right">42</td>
<td align="right">2</td>
<td align="right">4.8</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">d07[verb+able_reg]</td>
<td align="left">vary:variable | rely:reliable</td>
<td align="right">182</td>
<td align="right">6</td>
<td align="right">3.3</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">d08[verb+er_irreg]</td>
<td align="left">receive:receiver | promote:promoter</td>
<td align="right">702</td>
<td align="right">3</td>
<td align="right">0.4</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">d09[verb+tion_irreg]</td>
<td align="left">expire:expiration | deprive:deprivation</td>
<td align="right">552</td>
<td align="right">3</td>
<td align="right">0.5</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">d10[verb+ment_irreg]</td>
<td align="left">displace:displacement | align:alignment</td>
<td align="right">1722</td>
<td align="right">32</td>
<td align="right">1.9</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">e01[country-capital]</td>
<td align="left">kiev:ukraine | damascus:syria</td>
<td align="right">420</td>
<td align="right">27</td>
<td align="right">6.4</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">e02[country-language]</td>
<td align="left">bahamas:english | barbados:english</td>
<td align="right">342</td>
<td align="right">5</td>
<td align="right">1.5</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">e03[uk_city-county]</td>
<td align="left">cardiff:glamorgan | salisbury:wiltshire</td>
<td align="right">30</td>
<td align="right">0</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">e04[name-nationality]</td>
<td align="left">lincoln:american | mencius:chinese</td>
<td align="right">110</td>
<td align="right">3</td>
<td align="right">2.7</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">e05[name-occupation]</td>
<td align="left">plato:philosopher | lincoln:president</td>
<td align="right">56</td>
<td align="right">1</td>
<td align="right">1.8</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">e06[animal-young]</td>
<td align="left">panda:cub | trout:fingerling</td>
<td align="right">20</td>
<td align="right">0</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">e07[animal-sound]</td>
<td align="left">magpie:chatter | ferret:dook</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">e08[animal-shelter]</td>
<td align="left">fly:nest | cricket:nest</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">e09[things-color]</td>
<td align="left">ruby:red | broccoli:green</td>
<td align="right">72</td>
<td align="right">14</td>
<td align="right">19.4</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">e10[male-female]</td>
<td align="left">sir:madam | fox:vixen</td>
<td align="right">380</td>
<td align="right">225</td>
<td align="right">59.2</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">i01[noun-plural_reg]</td>
<td align="left">department:departments | director:directors</td>
<td align="right">2256</td>
<td align="right">459</td>
<td align="right">20.3</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">i02[noun-plural_irreg]</td>
<td align="left">academy:academies | variety:varieties</td>
<td align="right">2070</td>
<td align="right">198</td>
<td align="right">9.6</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">i03[adj-comparative]</td>
<td align="left">hot:hotter | tasty:tastier</td>
<td align="right">20</td>
<td align="right">11</td>
<td align="right">55.0</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">i04[adj-superlative]</td>
<td align="left">lazy:laziest | wealthy:wealthiest</td>
<td align="right">182</td>
<td align="right">47</td>
<td align="right">25.8</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">i05[verb_inf-3psg]</td>
<td align="left">suggest:suggests | appear:appears</td>
<td align="right">2256</td>
<td align="right">457</td>
<td align="right">20.3</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">i06[verb_inf-ving]</td>
<td align="left">protect:protecting | enjoy:enjoying</td>
<td align="right">2450</td>
<td align="right">307</td>
<td align="right">12.5</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">i07[verb_inf-ved]</td>
<td align="left">spend:spent | appear:appeared</td>
<td align="right">2450</td>
<td align="right">541</td>
<td align="right">22.1</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">i08[verb_ving-3psg]</td>
<td align="left">adding:adds | describing:describes</td>
<td align="right">2070</td>
<td align="right">242</td>
<td align="right">11.7</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">i09[verb_ving-ved]</td>
<td align="left">failing:failed | following:followed</td>
<td align="right">2450</td>
<td align="right">201</td>
<td align="right">8.2</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">i10[verb_3psg-ved]</td>
<td align="left">seems:seemed | represents:represented</td>
<td align="right">1980</td>
<td align="right">247</td>
<td align="right">12.5</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">l04[meronyms-substance]</td>
<td align="left">lawn:grass | beard:hair</td>
<td align="right">30</td>
<td align="right">0</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">l05[meronyms-member]</td>
<td align="left">policeman:police | listener:audience</td>
<td align="right">210</td>
<td align="right">7</td>
<td align="right">3.3</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">l06[meronyms-part]</td>
<td align="left">shilling:pence | byte:bit</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">l07[synonyms-intensity]</td>
<td align="left">sniffles:pneumonia | sea:ocean</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="even">
<td align="left">bats</td>
<td align="left">l08[synonyms-exact]</td>
<td align="left">monument:memorial | rock:stone</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
<tr class="odd">
<td align="left">bats</td>
<td align="left">l10[antonyms-binary]</td>
<td align="left">inhale:exhale | inbound:outbound</td>
<td align="right">30</td>
<td align="right">13</td>
<td align="right">43.3</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">capital-common-countries</td>
<td align="left">Ottawa:Canada | Bern:Switzerland</td>
<td align="right">132</td>
<td align="right">17</td>
<td align="right">12.9</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">capital-world</td>
<td align="left">Tegucigalpa:Honduras | Vaduz:Liechtenstein</td>
<td align="right">157</td>
<td align="right">10</td>
<td align="right">6.4</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">city-in-state</td>
<td align="left">Louisville:Kentucky | Milwaukee:Wisconsin</td>
<td align="right">202</td>
<td align="right">14</td>
<td align="right">6.9</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">currency</td>
<td align="left">India:rupee | Croatia:kuna</td>
<td align="right">28</td>
<td align="right">0</td>
<td align="right">0.0</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">family</td>
<td align="left">uncle:aunt | man:woman</td>
<td align="right">182</td>
<td align="right">133</td>
<td align="right">73.1</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">gram1-adjective-to-adverb</td>
<td align="left">rapid:rapidly | efficient:efficiently</td>
<td align="right">552</td>
<td align="right">13</td>
<td align="right">2.4</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">gram2-opposite</td>
<td align="left">reasonable:unreasonable | productive:unproductive</td>
<td align="right">210</td>
<td align="right">40</td>
<td align="right">19.0</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">gram3-comparative</td>
<td align="left">loud:louder | smart:smarter</td>
<td align="right">992</td>
<td align="right">387</td>
<td align="right">39.0</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">gram4-superlative</td>
<td align="left">good:best | bad:worst</td>
<td align="right">756</td>
<td align="right">149</td>
<td align="right">19.7</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">gram5-present-participle</td>
<td align="left">swim:swimming | invent:inventing</td>
<td align="right">870</td>
<td align="right">157</td>
<td align="right">18.0</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">gram6-nationality-adjective</td>
<td align="left">Slovakia:Slovakian | Egypt:Egyptian</td>
<td align="right">634</td>
<td align="right">80</td>
<td align="right">12.6</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">gram7-past-tense</td>
<td align="left">spending:spent | thinking:thought</td>
<td align="right">1406</td>
<td align="right">345</td>
<td align="right">24.5</td>
</tr>
<tr class="even">
<td align="left">google</td>
<td align="left">gram8-plural</td>
<td align="left">cloud:clouds | cat:cats</td>
<td align="right">702</td>
<td align="right">97</td>
<td align="right">13.8</td>
</tr>
<tr class="odd">
<td align="left">google</td>
<td align="left">gram9-plural-verbs</td>
<td align="left">describe:describes | generate:generates</td>
<td align="right">600</td>
<td align="right">50</td>
<td align="right">8.3</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Gladkova, A., Drozd, A., &amp; Matsuoka, S. (2016, June). Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn’t. In <em>Proceedings of the NAACL Student Research Workshop</em> (pp. 8-15).</p>
<p>Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. <em>arXiv preprint arXiv:1301.3781</em>.</p>
</div>
